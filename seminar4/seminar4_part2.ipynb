{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometrical Methods in Machine Learning\n",
    "## Seminar 5: Manifold Learning Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import offsetbox\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits, fetch_olivetti_faces, make_moons, make_circles, fetch_mldata\n",
    "from sklearn.datasets.samples_generator import make_swiss_roll\n",
    "\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.manifold import Isomap, LocallyLinearEmbedding, SpectralEmbedding\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Swiss roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X, color = make_swiss_roll(n_samples=1000, random_state=123, noise=0.01)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.view_init(10, -80)\n",
    "ax.scatter(X[:, 0], X[:, 1], X[:, 2])\n",
    "plt.title('Swiss Roll in 3D')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = # your code here\n",
    "X_pca = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.grid(linestyle=\"dotted\")\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=color, cmap=plt.cm.rainbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Kernel PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = # your code here\n",
    "X_kpca = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.grid(linestyle=\"dotted\")\n",
    "plt.scatter(X_kpca[:, 0], X_kpca[:, 1], c=color, cmap=plt.cm.rainbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDS\n",
    "\n",
    "#### Intuition\n",
    "\n",
    "Embedding should preserve distances between points.\n",
    "\n",
    "$$J_{MDS}(z_1, \\dots, z_n) = \\sum_{ij}^n ((x_i, x_j) - (z_i, z_j))^2$$\n",
    "\n",
    "#### Algorithm\n",
    "\n",
    "Given a dataset $X = \\{x_1, \\dots, x_n \\} \\in \\mathbb{R}^{D \\times n}$,\n",
    "\n",
    "1. Compute Gram matrix of $G \\in \\mathbb{R}^{n \\times n}$, s.t. $g_{ij} = (x_i, x_j) = X^TX$\n",
    "2. Find $d$ eigenvectors $\\{ v_1, \\dots, v_d \\} \\in \\mathbb{R}^{n \\times d}$ of $G$, corresponding to $d$ largest eigenvalues: $\\Lambda = diag(\\lambda_1, \\dots, \\lambda_d) \\in \\mathbb{R}^{d \\times d}$.\n",
    "3. Compute the embedding $\\{z_1, \\dots, z_n \\} = \\Lambda^{1/2} \\{ v_1, \\dots, v_d \\}^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Isomap\n",
    "\n",
    "#### Intuition\n",
    "\n",
    "Manifold is globally isometric to a convex subset of Euclidean space.\n",
    "\n",
    "#### Algorithm\n",
    "\n",
    "Given a dataset $X = \\{x_1, \\dots, x_n \\} \\in \\mathbb{R}^{D \\times n}$,\n",
    "\n",
    "1. Estimate the neighborhood $\\mathcal{N}_i$ of each point, eigher within $\\varepsilon$-ball or take $k$ nearest neighbors.\n",
    "2. Build a graph on points, with adjancency matrix $A$, s.t. $a_{ij} = 1$ if the points are neighbors and $0$ otherwise.\n",
    "3. Estimate pairwise geodesic distances between any two points, by shortest paths between nodes of the graph.\n",
    "4. Perform MDS on pairwise distance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Isomap(n_components=2)\n",
    "X_isomap = model.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.grid(linestyle=\"dotted\")\n",
    "plt.scatter(X_isomap[:, 0], X_isomap[:, 1], c=color, cmap=plt.cm.rainbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Locally Linear Embedding\n",
    "\n",
    "#### Intuition\n",
    "\n",
    "Manifold is locally linear. The same weights that reconstruct the datapoints in $D$ dimensions should reconstruct it in the manifold in $d$ dimensions.\n",
    "\n",
    "#### Algorithm\n",
    "\n",
    "Given a dataset $X = \\{x_1, \\dots, x_n \\} \\in \\mathbb{R}^D$,\n",
    "\n",
    "- Estimate the neighborhood $\\mathcal{N}_i$ of each point, eigher within $\\varepsilon$-ball or take $k$ nearest neighbors.\n",
    "- \n",
    "\n",
    "$$W = \\arg \\min_W \\sum_i^n \\| x_i - \\sum_j^n W_{ij} x_j \\|^2, \\\\\n",
    "s.t. \\sum_j^n W_{ij} = 1, \\forall i, \\\\\n",
    "W_{ij} = 0, x_j \\notin \\mathcal{N}_i$$\n",
    "\n",
    "- Given the weights W, find the embedded points:\n",
    "\n",
    "$$\\{z_1, \\dots, z_n\\} = \\arg \\min_{\\{z_1, \\dots, z_n\\}} \\sum_i^n \\| z_i - \\sum_i^n W_{ij} z_j \\|^2 \\\\\n",
    "s.t. \\sum_i^n z_i = 0\\\\\n",
    "cov(Z) = \\mathbb{I}$$\n",
    "\n",
    "The same weights that reconstruct the datapoints in $D$ dimensions should reconstruct it in the manifold in $d$ dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LocallyLinearEmbedding(n_components=2, n_neighbors=11)\n",
    "X_lle = model.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.grid(linestyle=\"dotted\")\n",
    "plt.scatter(X_lle[:, 0], X_lle[:, 1], c=color, cmap=plt.cm.rainbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Laplacian Eigenmaps\n",
    "\n",
    "#### Intuition\n",
    "\n",
    "Manifold can be reconstructed with computing Laplacian of the graph, which is empirical version of Laplace-Beltrami operator of smooth manifold.\n",
    "\n",
    "#### Algorithm\n",
    "\n",
    "Given a dataset $X = \\{x_1, \\dots, x_n \\} \\in \\mathbb{R}^{D \\times n}$,\n",
    "\n",
    "1. Estimate the neighborhood $\\mathcal{N}_i$ of each point, eigher within $\\varepsilon$-ball or take $k$ nearest neighbors.\n",
    "2. Build adjancency graph, with adjacency matrix $A$ s.t.\n",
    "\n",
    "$$a_{ij} = \\exp(\\lambda \\| x_i - x_j \\|^2), if x_j \\in \\mathcal{N}_i \\\\\n",
    "a_{ij} = 0, otherwise$$\n",
    "\n",
    "3. Compute graph Laplacian $L = D - A \\in \\mathbb{R}^{n \\times n}$, where $D$ s.t. $d_{ii} = \\sum_i^n A_{ij}$ and solve eigenvalue problem: \n",
    "\n",
    "$$Lv = \\lambda Dv,\\\\\n",
    "v \\in \\mathbb{R}^n$$\n",
    "\n",
    "Given $d+1$ eigenvectors, corresponding to _smallest_ eigenvalues, compute the emdedding:\n",
    "\n",
    "$$\\{z_1, \\dots, z_n \\} = \\{f_1(i), \\dots, f_d(i)\\}^T \\in \\mathbb{R}^d$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpectralEmbedding(n_components=2, n_neighbors=31)\n",
    "X_le = model.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.grid(linestyle=\"dotted\")\n",
    "plt.scatter(X_le[:, 0], X_le[:, 1], c=color, cmap=plt.cm.rainbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Local Tangent Space Alignment\n",
    "\n",
    "#### Intuition\n",
    "\n",
    "Local linearity assumption. Manifold can be approximated using tangent spaces to each point.\n",
    "\n",
    "#### Algorithm\n",
    "\n",
    "Given a dataset $X = \\{x_1, \\dots, x_n \\} \\in \\mathbb{R}^{D \\times n}$,\n",
    "\n",
    "1. Estimate the neighborhood $\\mathcal{N}_i$ of each point, eigher within $\\varepsilon$-ball or take $k$ nearest neighbors.\n",
    "2. Build a graph on points, with adjancency matrix $A$, s.t. $a_{ij} = 1$ if the points are neighbors and $0$ otherwise.\n",
    "3. Estimate tangent spaces to each point using Local PCA, align tangent spaces.\n",
    "4. Compute the embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LocallyLinearEmbedding(n_components=2, n_neighbors=15, method=\"ltsa\")\n",
    "X_ltsa = model.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.grid(linestyle=\"dotted\")\n",
    "plt.scatter(X_ltsa[:, 0], X_ltsa[:, 1], c=color, cmap=plt.cm.rainbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the performance\n",
    "\n",
    "To evaluate the performance of manifold learning algorithms implement neighborhood preserving ratio (NPR) metric, which is defined as follows:\n",
    "\n",
    "$$NPR = \\frac{1}{kn} \\sum_{i=1}^n \\left|\\mathcal{N}_k(x_i) \\bigcap \\mathcal{N}_k(z_i) \\right|,$$\n",
    "\n",
    "where $n$ is the number of data points, $\\mathcal{N}_k(x_i)$ is the set of $k$-nearest neighbors of data points $x_i$ of original dimension and $\\mathcal{N}_k(z_i)$ is the set of $k$-nearest neighbors of $z_i$ of reduced dimension. $|\\cdot|$ represents the number of intersection points.\n",
    "\n",
    "**Exercise:** Evaluate manifold learning methods performance using NPR as a metric on swiss roll for 3 different values of $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NPR(X, Z):\n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [X_pca, X_kpca, X_isomap, X_lle, X_le, X_ltsa]\n",
    "\n",
    "k = 21\n",
    "n = X.shape[0]\n",
    "\n",
    "for z in data:\n",
    "    # your code here\n",
    "    \n",
    "    print(npr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_digits(return_X_y=True)\n",
    "shape = (int(np.sqrt(X.shape[1])), int(np.sqrt(X.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot numbers\n",
    "_, ax = plt.subplots(10, 10, figsize=(6, 6),\n",
    "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "\n",
    "for i, a in enumerate(ax.flat):\n",
    "    a.imshow(X[i].reshape(shape), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n components, k nearest neighbors\n",
    "n, k = 2, 15\n",
    "\n",
    "models = [\n",
    "    (\"PCA\", PCA(n_components=n)),\n",
    "    (\"Isomap\", Isomap(n_components=n, n_neighbors=k)),\n",
    "    (\"LLE\", LocallyLinearEmbedding(n_components=n, n_neighbors=k)),\n",
    "    (\"Laplacian Eignenmaps\", SpectralEmbedding(n_components=n, n_neighbors=k))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,25))\n",
    "\n",
    "for key, model in enumerate(models):\n",
    "    X_transformed = MinMaxScaler().fit_transform(model[1].fit_transform(X))\n",
    "    plt.subplot(320 + (key+1))\n",
    "    plt.title(model[0])\n",
    "    plt.grid(linestyle=\"dotted\")\n",
    "    plt.scatter(X_transformed[:, 0], X_transformed[:, 1], alpha=0.5, s=10, c=y, cmap=plt.cm.rainbow)\n",
    "    \n",
    "    # plot images\n",
    "    ax = plt.gca()\n",
    "    for i in range(0, X.shape[0], 10):\n",
    "        box = offsetbox.AnnotationBbox(offsetbox.OffsetImage(X[i].reshape(shape), cmap=\"gray\", zoom=1.5), X_transformed[i], frameon=False)\n",
    "        ax.add_artist(box)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST original')\n",
    "train_size = 60000\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "mnist.data[:train_size,:], mnist.data[train_size:,:], \\\n",
    "mnist.target[:train_size], mnist.target[train_size:]\n",
    "\n",
    "print(\"Dataset summary:\\nSamples: {}, features: {}, classes: {}\"\n",
    "      .format(X_train.shape[0] + X_test.shape[0], X_train.shape[1], np.unique(y_train).shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** explore manifolds of different digits, try to interpreted embedding coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_test[y_test==1]\n",
    "shape = (int(np.sqrt(X.shape[1])), int(np.sqrt(X.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot numbers\n",
    "_, ax = plt.subplots(10, 10, figsize=(6, 6),\n",
    "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "\n",
    "for i, a in enumerate(ax.flat):\n",
    "    a.imshow(X[i].reshape(shape), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n components, k nearest neighbors\n",
    "n, k = 2, 15\n",
    "\n",
    "models = [\n",
    "    (\"PCA\", PCA(n_components=n)),\n",
    "    (\"Isomap\", Isomap(n_components=n, n_neighbors=k)),\n",
    "    (\"LLE\", LocallyLinearEmbedding(n_components=n, n_neighbors=k)),\n",
    "    (\"Laplacian Eignenmaps\", SpectralEmbedding(n_components=n, n_neighbors=k))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,25))\n",
    "\n",
    "for key, model in enumerate(models):\n",
    "    X_transformed = MinMaxScaler().fit_transform(model[1].fit_transform(X))\n",
    "    plt.subplot(320 + (key+1))\n",
    "    plt.title(model[0])\n",
    "    plt.grid(linestyle=\"dotted\")\n",
    "    #plt.scatter(X_transformed[:, 0], X_transformed[:, 1], alpha=0.5, s=10)\n",
    "    \n",
    "    # plot images\n",
    "    ax = plt.gca()\n",
    "    for i in range(0, X.shape[0], 10):\n",
    "        box = offsetbox.AnnotationBbox(offsetbox.OffsetImage(X[i].reshape(shape), cmap=plt.cm.get_cmap('gray'), zoom=0.75), X_transformed[i], frameon=False)\n",
    "        ax.add_artist(box)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Airfoils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_points = np.loadtxt('../seminar1/data/ref_points.csv', delimiter=',')\n",
    "X = np.loadtxt('../seminar1/data/airfoils.csv', delimiter=',')\n",
    "X_oos = np.loadtxt('../seminar1/data/test_afl.csv', delimiter=',').reshape(1, -1)\n",
    "X.shape, X_oos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n components, k nearest neighbors\n",
    "n, k = 2, 15\n",
    "\n",
    "models = [\n",
    "    (\"PCA\", PCA(n_components=n)),\n",
    "    (\"Isomap\", Isomap(n_components=n, n_neighbors=k)),\n",
    "    (\"LLE\", LocallyLinearEmbedding(n_components=n, n_neighbors=k)),\n",
    "    (\"Laplacian Eignenmaps\", SpectralEmbedding(n_components=n, n_neighbors=k))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,25))\n",
    "\n",
    "# color, proportional to height-to-width ratio\n",
    "colors = MinMaxScaler().fit_transform((np.max(X[:, :], axis=1) - np.min(X[:, :], axis=1)).reshape(-1, 1)).ravel()\n",
    "\n",
    "for key, value in enumerate(models):\n",
    "    X_transformed = MinMaxScaler().fit_transform(value[1].fit_transform(X))\n",
    "    plt.subplot(320 + (key+1))\n",
    "    plt.title(value[0])\n",
    "    plt.grid(linestyle=\"dotted\")\n",
    "    plt.scatter(X_transformed[:, 0], X_transformed[:, 1], c=colors, cmap=\"Reds\")\n",
    "    \n",
    "    for i in range(0, 199, 10):\n",
    "        plt.plot(X_transformed[i, 0] + ref_points / 4, X_transformed[i, 1] + X[i, :] / 2, '-', label = 'Airfoil #' + str(i), c='k', alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Out-of-Sample extension\n",
    "\n",
    "**Exercise:** Which methods have OoS extensions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = # your code here\n",
    "\n",
    "X_transformed = # your code here\n",
    "X_transformed_oos = # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data\n",
    "scaler = MinMaxScaler().fit(X_transformed)\n",
    "X_transformed = scaler.transform(X_transformed)\n",
    "X_transformed_oos = scaler.transform(X_transformed_oos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.grid(linestyle=\"dotted\")\n",
    "plt.scatter(X_transformed[:, 0], X_transformed[:, 1], c=colors, cmap=\"Reds\")\n",
    "    \n",
    "for i in range(0, 199, 10):\n",
    "    plt.plot(X_transformed[i, 0] + ref_points / 4, X_transformed[i, 1] + X[i, :] / 2, '-', c='k', alpha=0.5)\n",
    "\n",
    "plt.plot(X_transformed_oos[0, 0] + ref_points / 4, X_transformed_oos[0, 1] + X_oos[0, :] / 2, '-', c='b', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluating the performance\n",
    "\n",
    "**Exercise:** Evaluate manifold learning methods performance using NPR as a metric on digits or MNIST and airfoils for 3 different values of $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
